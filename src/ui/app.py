"""
Document Assistant Web UI
Gradio ê¸°ë°˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
"""
import os
import gradio as gr
from pathlib import Path
from typing import List, Tuple, Optional, Generator
import time

import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.document.document_processor import DocumentProcessor
from src.vector.vector_manager import VectorManager
from src.vector.incremental_manager import IncrementalManager
from src.llm.model_manager import ModelManager
from src.rag.rag_pipeline import RAGPipeline
from config.settings import MODELS_PATH


class DocumentAssistantUI:
    """ë¬¸ì„œ ë„ìš°ë¯¸ UI í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.doc_processor = DocumentProcessor()
        self.vector_manager = VectorManager()
        self.model_manager = ModelManager()
        self.rag_pipeline: Optional[RAGPipeline] = None
        self.current_collection: Optional[str] = None
        
    def get_model_choices(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
        models = self.model_manager.list_models()
        if not models:
            return ["ëª¨ë¸ ì—†ìŒ - data/models/ í´ë”ì— GGUF íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”"]
        return [f"{m.name} ({m.size_gb}GB)" for m in models]
    
    def get_collection_choices(self) -> List[str]:
        """ì¸ë±ì‹±ëœ ì»¬ë ‰ì…˜ ëª©ë¡"""
        collections = self.vector_manager.list_collections()
        if not collections:
            return []
        
        result = []
        for coll in collections:
            stats = self.vector_manager.get_collection_stats(coll)
            doc_count = stats.get('document_count', 0)
            result.append(f"{coll} ({doc_count} chunks)")
        return result
    
    def scan_and_index(
        self, 
        folder_path: str, 
        collection_name: str,
        progress=gr.Progress()
    ) -> str:
        """í´ë” ìŠ¤ìº” ë° ë²¡í„°í™”"""
        if not folder_path or not os.path.exists(folder_path):
            return "âŒ ìœ íš¨í•œ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        
        if not collection_name:
            # í´ë” ì´ë¦„ì„ ì»¬ë ‰ì…˜ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
            collection_name = Path(folder_path).name
        
        # ì»¬ë ‰ì…˜ ì´ë¦„ ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        collection_name = "".join(c if c.isalnum() or c == "_" else "_" for c in collection_name)
        
        try:
            # ì¦ë¶„ ê´€ë¦¬ì ì´ˆê¸°í™”
            inc_manager = IncrementalManager(collection_name)
            changes = inc_manager.get_changes(folder_path)
            
            if not changes.has_changes():
                return f"âœ… ë³€ê²½ ì‚¬í•­ ì—†ìŒ. ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.\nğŸ“Š ì¸ë±ì‹±ëœ íŒŒì¼: {inc_manager.get_indexed_count()}ê°œ"
            
            progress(0, desc="íŒŒì¼ ìŠ¤ìº” ì¤‘...")
            
            # ì‚­ì œëœ íŒŒì¼ ì²˜ë¦¬
            if changes.deleted:
                progress(0.1, desc=f"ì‚­ì œëœ íŒŒì¼ ì²˜ë¦¬ ì¤‘... ({len(changes.deleted)}ê°œ)")
                self.vector_manager.remove_documents_by_source(changes.deleted, collection_name)
                inc_manager.remove_file_metadata(changes.deleted)
            
            # ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ ì²˜ë¦¬
            files_to_process = changes.added + changes.modified
            total_files = len(files_to_process)
            
            if total_files == 0:
                return f"âœ… ì‚­ì œëœ íŒŒì¼ë§Œ ì²˜ë¦¬ë¨ ({len(changes.deleted)}ê°œ)"
            
            all_documents = []
            for idx, file_path in enumerate(files_to_process):
                progress((idx + 1) / total_files, desc=f"ì²˜ë¦¬ ì¤‘: {file_path.name}")
                
                # ìˆ˜ì •ëœ íŒŒì¼ì€ ê¸°ì¡´ ë²¡í„° ì‚­ì œ
                if file_path in changes.modified:
                    self.vector_manager.remove_documents_by_source([str(file_path)], collection_name)
                
                docs = self.doc_processor.load_document(file_path)
                all_documents.extend(docs)
            
            # ì²­í¬ ë¶„í• 
            progress(0.9, desc="ë¬¸ì„œ ì²­í¬ ë¶„í•  ì¤‘...")
            if all_documents:
                chunked_docs = self.doc_processor.text_splitter.split_documents(all_documents)
                
                # ë²¡í„° DBì— ì €ì¥
                progress(0.95, desc="ë²¡í„° DBì— ì €ì¥ ì¤‘...")
                added_count = self.vector_manager.add_documents(chunked_docs, collection_name)
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                inc_manager.update_files_metadata(files_to_process)
            else:
                added_count = 0
            
            progress(1.0, desc="ì™„ë£Œ!")
            
            result = f"""âœ… ì¸ë±ì‹± ì™„ë£Œ!

ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:
- ì»¬ë ‰ì…˜: {collection_name}
- ì¶”ê°€ëœ íŒŒì¼: {len(changes.added)}ê°œ
- ìˆ˜ì •ëœ íŒŒì¼: {len(changes.modified)}ê°œ
- ì‚­ì œëœ íŒŒì¼: {len(changes.deleted)}ê°œ
- ìƒì„±ëœ ì²­í¬: {added_count}ê°œ
- ì´ ì¸ë±ì‹± íŒŒì¼: {inc_manager.get_indexed_count()}ê°œ"""
            
            self.current_collection = collection_name
            return result
            
        except Exception as e:
            return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def load_model(self, model_selection: str, progress=gr.Progress()) -> str:
        """ëª¨ë¸ ë¡œë“œ"""
        if not model_selection or "ëª¨ë¸ ì—†ìŒ" in model_selection:
            return "âŒ ë¨¼ì € ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
        
        try:
            # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ (í¬ê¸° ì •ë³´ ì œê±°)
            model_name = model_selection.split(" (")[0]
            
            progress(0.3, desc="ëª¨ë¸ ë¡œë”© ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            self.model_manager.load_model(model_name)
            progress(1.0, desc="ì™„ë£Œ!")
            
            return f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}"
        except Exception as e:
            return f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
    
    def setup_rag(self, collection_selection: str) -> str:
        """RAG íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        if not collection_selection:
            return "âŒ ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”."
        
        try:
            # ì»¬ë ‰ì…˜ ì´ë¦„ ì¶”ì¶œ
            collection_name = collection_selection.split(" (")[0]
            
            self.rag_pipeline = RAGPipeline(self.vector_manager, self.model_manager)
            self.rag_pipeline.setup_chain(collection_name)
            self.current_collection = collection_name
            
            return f"âœ… RAG ì„¤ì • ì™„ë£Œ: {collection_name}"
        except Exception as e:
            return f"âŒ RAG ì„¤ì • ì‹¤íŒ¨: {str(e)}"
    
    def chat(
        self, 
        message: str, 
        history: List[Tuple[str, str]]
    ) -> Tuple[List[Tuple[str, str]], str]:
        """ì±„íŒ… ì‘ë‹µ"""
        if not message:
            return history, ""
        
        if not self.rag_pipeline:
            history.append((message, "âŒ ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì»¬ë ‰ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”."))
            return history, ""
        
        try:
            # ì§ˆì˜ì‘ë‹µ (ì†ŒìŠ¤ í¬í•¨)
            result = self.rag_pipeline.query_with_sources(message)
            answer = result["answer"]
            
            # ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
            if result["sources"]:
                sources_text = "\n\nğŸ“ **ì°¸ê³  ë¬¸ì„œ:**\n"
                for src in result["sources"][:3]:  # ìƒìœ„ 3ê°œë§Œ
                    sources_text += f"- {src['filename']}\n"
                answer += sources_text
            
            history.append((message, answer))
            return history, ""
        except Exception as e:
            history.append((message, f"âŒ ì˜¤ë¥˜: {str(e)}"))
            return history, ""
    
    def search_docs(self, query: str) -> str:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        if not query:
            return "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        
        if not self.current_collection:
            return "âŒ ë¨¼ì € ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”."
        
        try:
            if not self.rag_pipeline:
                self.rag_pipeline = RAGPipeline(self.vector_manager, self.model_manager)
            
            results = self.rag_pipeline.search_similar_documents(
                query, 
                self.current_collection,
                k=5
            )
            
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            output = "ğŸ” **ê²€ìƒ‰ ê²°ê³¼:**\n\n"
            for i, r in enumerate(results, 1):
                output += f"**{i}. {r['filename']}** (ìœ ì‚¬ë„: {r['score']:.4f})\n"
                output += f"```\n{r['preview']}\n```\n\n"
            
            return output
        except Exception as e:
            return f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
    
    def import_model_file(self, file) -> str:
        """ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ"""
        if file is None:
            return "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”."
        
        try:
            result = self.model_manager.import_model(file.name)
            return f"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ: {Path(result).name}"
        except Exception as e:
            return f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}"


def create_app() -> gr.Blocks:
    """Gradio ì•± ìƒì„±"""
    ui = DocumentAssistantUI()
    
    with gr.Blocks(title="ğŸ“š Document Assistant") as app:
        gr.Markdown("# ğŸ“š Document Assistant")
        gr.Markdown("ë¬¸ì„œ ê¸°ë°˜ RAG ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ - ê¸°íšì„œ, ì„¤ê³„ì„œ ë¶„ì„ ë° ì‘ì„± ì§€ì›")
        
        with gr.Row():
            # ì™¼ìª½ íŒ¨ë„: ì„¤ì •
            with gr.Column(scale=1):
                gr.Markdown("## âš™ï¸ ì„¤ì •")
                
                # í´ë” ì¸ë±ì‹±
                with gr.Group():
                    gr.Markdown("### ğŸ“ ë¬¸ì„œ í´ë”")
                    folder_input = gr.Textbox(
                        label="í´ë” ê²½ë¡œ",
                        placeholder="C:/Documents/Projects",
                        info="ì¸ë±ì‹±í•  ë¬¸ì„œ í´ë” ê²½ë¡œ"
                    )
                    collection_input = gr.Textbox(
                        label="ì»¬ë ‰ì…˜ ì´ë¦„ (ì„ íƒ)",
                        placeholder="my_project",
                        info="ë¹„ì›Œë‘ë©´ í´ë” ì´ë¦„ ì‚¬ìš©"
                    )
                    scan_btn = gr.Button("ğŸ” ìŠ¤ìº” ë° ì¸ë±ì‹±", variant="primary")
                    index_status = gr.Textbox(
                        label="ì¸ë±ì‹± ìƒíƒœ",
                        lines=8,
                        interactive=False,
                        elem_classes=["status-box"]
                    )
                
                # ëª¨ë¸ ì„ íƒ
                with gr.Group():
                    gr.Markdown("### ğŸ¤– LLM ëª¨ë¸")
                    model_dropdown = gr.Dropdown(
                        choices=ui.get_model_choices(),
                        label="ëª¨ë¸ ì„ íƒ",
                        info="data/models/ í´ë”ì˜ GGUF íŒŒì¼"
                    )
                    refresh_models_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨")
                    load_model_btn = gr.Button("ğŸ“¥ ëª¨ë¸ ë¡œë“œ", variant="primary")
                    model_status = gr.Textbox(
                        label="ëª¨ë¸ ìƒíƒœ",
                        interactive=False
                    )
                    
                    with gr.Accordion("ëª¨ë¸ ì—…ë¡œë“œ", open=False):
                        model_upload = gr.File(
                            label="GGUF íŒŒì¼ ì—…ë¡œë“œ",
                            file_types=[".gguf", ".bin"]
                        )
                        upload_btn = gr.Button("ì—…ë¡œë“œ")
                        upload_status = gr.Textbox(label="ì—…ë¡œë“œ ìƒíƒœ", interactive=False)
                
                # ì»¬ë ‰ì…˜ ì„ íƒ
                with gr.Group():
                    gr.Markdown("### ğŸ“‚ ì»¬ë ‰ì…˜")
                    collection_dropdown = gr.Dropdown(
                        choices=ui.get_collection_choices(),
                        label="í™œì„± ì»¬ë ‰ì…˜ ì„ íƒ"
                    )
                    refresh_collections_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨")
                    setup_rag_btn = gr.Button("âš¡ RAG í™œì„±í™”", variant="primary")
                    rag_status = gr.Textbox(label="RAG ìƒíƒœ", interactive=False)
            
            # ì˜¤ë¥¸ìª½ íŒ¨ë„: ì±„íŒ…
            with gr.Column(scale=2):
                gr.Markdown("## ğŸ’¬ ì§ˆì˜ì‘ë‹µ")
                
                chatbot = gr.Chatbot(
                    label="ëŒ€í™”",
                    height=400
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        label="ì§ˆë¬¸ ì…ë ¥",
                        placeholder="ì˜ˆ: ê¸°íšì„œ ì–‘ì‹ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                        scale=4
                    )
                    send_btn = gr.Button("ì „ì†¡", variant="primary", scale=1)
                
                clear_btn = gr.Button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”")
                
                # ë¬¸ì„œ ê²€ìƒ‰
                with gr.Accordion("ğŸ” ë¬¸ì„œ ê²€ìƒ‰", open=False):
                    search_input = gr.Textbox(
                        label="ê²€ìƒ‰ì–´",
                        placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œ ì…ë ¥"
                    )
                    search_btn = gr.Button("ê²€ìƒ‰")
                    search_results = gr.Markdown(label="ê²€ìƒ‰ ê²°ê³¼")
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        scan_btn.click(
            ui.scan_and_index,
            inputs=[folder_input, collection_input],
            outputs=[index_status]
        ).then(
            lambda: ui.get_collection_choices(),
            outputs=[collection_dropdown]
        )
        
        refresh_models_btn.click(
            lambda: gr.update(choices=ui.get_model_choices()),
            outputs=[model_dropdown]
        )
        
        load_model_btn.click(
            ui.load_model,
            inputs=[model_dropdown],
            outputs=[model_status]
        )
        
        upload_btn.click(
            ui.import_model_file,
            inputs=[model_upload],
            outputs=[upload_status]
        ).then(
            lambda: gr.update(choices=ui.get_model_choices()),
            outputs=[model_dropdown]
        )
        
        refresh_collections_btn.click(
            lambda: gr.update(choices=ui.get_collection_choices()),
            outputs=[collection_dropdown]
        )
        
        setup_rag_btn.click(
            ui.setup_rag,
            inputs=[collection_dropdown],
            outputs=[rag_status]
        )
        
        # ì±„íŒ… ì´ë²¤íŠ¸
        msg_input.submit(
            ui.chat,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
        send_btn.click(
            ui.chat,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, msg_input]
        )
        clear_btn.click(lambda: [], outputs=[chatbot])
        
        # ê²€ìƒ‰ ì´ë²¤íŠ¸
        search_btn.click(
            ui.search_docs,
            inputs=[search_input],
            outputs=[search_results]
        )
    
    return app


if __name__ == "__main__":
    app = create_app()
    app.launch(server_name="127.0.0.1", server_port=7860)
